# SmartSession_AI
â€œAn AI-driven classroom assistant that helps teachers understand when students are confused, distracted, or off-screen â€” without being invasive â€” using live video analytics and WebSockets.â€


# ðŸ§  SmartSession â€” Real-Time Student Engagement & Proctoring System

SmartSession is a real-time AI-powered web system that analyzes a studentâ€™s webcam feed to detect:

âœ… Confusion  
âœ… Engagement level  
âœ… Proctoring / integrity risks  

The teacher dashboard receives telemetry instantly and shows live student status.

This project was built for the **nSkills SmartSession Selection Challenge**.

---

## ðŸŽ¯ Objective

SmartSession is designed to help teachers understand:

âœ” When a student is confused  
âœ” Whether the student is attentive  
âœ” Whether multiple people or suspicious behavior is detected  

The goal is **support â€” not policing.**

---

## ðŸ“Œ Features

### ðŸŽ“ Student Portal
- Captures webcam feed
- Runs ML analysis
- Detects:
  - Confusion
  - Gaze direction
  - Missing face
  - Multiple faces
- Sends telemetry via **WebSockets**

---

### ðŸ‘¨â€ðŸ« Teacher Dashboard
- Shows **real-time student status**
- Status colors:
  - ðŸŸ¢ Focused
  - ðŸŸ¡ Confused
  - ðŸ”´ Proctor Alert
- Live timeline graph
- Zero-refresh updates

---

### ðŸ¤– AI / ML Engine (Python)
Uses:

- MediaPipe Face Mesh  
- MediaPipe Face Detection  
- OpenCV  
- FER emotion model  
- Custom confusion-score logic  
- Time-based gaze tracking  

---

## ðŸ— System Architecture

```
Student Frontend â†’ WebSocket â†’ FastAPI Backend â†’ ML Engine
                                            â†“
                                  Teacher Dashboard
```

WebSockets are used for **low-latency live telemetry.**

---

## ðŸ“‚ Project Structure

```
smartsession/
 â”œâ”€â”€ Backend/
 â”‚   â”œâ”€â”€ main.py
 â”‚   â”œâ”€â”€ websocket.py
 â”‚   â”œâ”€â”€ report.py
 â”‚   â”œâ”€â”€ models.py
 â”‚   â”œâ”€â”€ schemas.py
 â”‚   â”œâ”€â”€ database.py
 â”‚   â”œâ”€â”€ requirements.txt
 â”‚   â””â”€â”€ ml/
 â”‚       â”œâ”€â”€ confusion.py
 â”‚       â””â”€â”€ proctor.py
 â”‚
 â”œâ”€â”€ Frontend/
 â”‚   â”œâ”€â”€ pages/
 â”‚   â”œâ”€â”€ components/
 â”‚   â”œâ”€â”€ styles/
 â”‚   â”œâ”€â”€ api.js
 â”‚   â”œâ”€â”€ package.json
 â”‚   â””â”€â”€ package-lock.json
 â”‚
 â”œâ”€â”€ README.md
 â””â”€â”€ .gitignore
```

---

# âš™ï¸ Backend Setup â€” FastAPI

### Create virtual environment
```bash
cd Backend
python -m venv venv
```

Activate:

Windows:
```bash
venv\Scripts\activate
```

Mac/Linux:
```bash
source venv/bin/activate
```

---

### Install dependencies
```bash
pip install -r requirements.txt
```

---

### Run backend
```bash
uvicorn main:app --reload
```

Backend runs at:
```
http://localhost:8000
```

---

# ðŸŽ¨ Frontend Setup â€” Next.js / React

```bash
cd Frontend
npm install
npm run dev
```

Frontend runs at:
```
http://localhost:3000
```

---

# ðŸ§  AI / ML Engine â€” How Detection Works

The ML engine performs:

âœ” Face detection  
âœ” Gaze direction estimation  
âœ” Emotion probability extraction  
âœ” Custom confusion-score calculation  
âœ” Time-based proctor checks  

---

## ðŸ§© Confusion Detection â€” My Custom Logic

Confusion is **not directly predicted by FER.**  
So I implemented a **confusion-score** combining three signals:

| Signal | Source | Meaning |
|--------|--------|--------|
| Eyebrow contraction | MediaPipe Face Mesh | Cognitive strain |
| Happiness probability | FER | Emotional tone |
| Head tilt | Landmark symmetry | Uncertainty posture |

Implementation:

```
Backend/ml/confusion.py
```

---

### ðŸŽ¯ Landmarks Used

| ID | Use |
|----|----|
| 133 / 362 | Eye centers (scale reference) |
| 70 / 300 | Inner eyebrows (brow contraction) |
| 234 / 454 | Ear height (tilt detection) |

Eye-to-eye distance is used for **scale normalization** so results donâ€™t change with camera distance.

---

## ðŸ§® Confusion Score Formula

```python
confusion_score = (
    0.45 * (1 - brow_norm) +
    0.35 * (1 - happy_norm) +
    0.20 * tilt_norm
)
```

Where:

### âœ” `brow_norm`

```
brow_norm = brow_dist / 3.5
```

Lower spacing â†’ higher confusion.

Converted to confusion weight:

```
1 - brow_norm
```

---

### âœ” `happy_norm`

```
happy_norm = clamp(happy_prob, 0..1)
```

Lower happiness â†’ higher confusion-weight.

---

### âœ” `tilt_norm`

```
tilt_norm = abs(L_ear.y - R_ear.y) / face_scale
```

---

## ðŸŽ¯ Final Decision Rule

```python
confused = confusion_score >= 0.58
```

| Score | Meaning |
|------|--------|
| 0.00 â€“ 0.30 | Confident |
| 0.30 â€“ 0.57 | Neutral |
| â‰¥ 0.58 | **Confused** |

Function returns:

```
confused: bool
confusion_score: float (0â€“1)
```

This makes confusion **explainable and deterministic.**

---

# ðŸ›¡ Proctoring & Integrity Detection

Implementation:

```
Backend/ml/proctor.py
```

Uses:

âœ” MediaPipe Face Detection â†’ face count  
âœ” MediaPipe Face Mesh â†’ gaze  
âœ” FER â†’ emotional cues  
âœ” Timer logic â†’ prevents false alerts  

---

## ðŸ‘¥ Face Count Rules

| Condition | Status |
|----------|-------|
| 0 faces | `NO PERSON` |
| >1 face | `MULTIPLE PEOPLE` |
| 1 face | `OK` |

---

## ðŸ‘ Gaze Direction Detection

Computed using **nose vs eye-center offset**:

```
RIGHT  â†’ yaw >  0.05
LEFT   â†’ yaw < -0.05
DOWN   â†’ pitch > 0.05
UP     â†’ pitch < -0.05
CENTER â†’ otherwise
```

---

## â³ 4-Second Gaze Violation

If gaze â‰  center:

âœ” Start timer  
âœ” If still away after **4 seconds â†’ Proctor Alert**  
âœ” Reset on return  

This avoids false alerts from quick glances.

---

## ðŸ™‚ Emotion Classification (FER)

| Rule | Meaning |
|------|--------|
| happy > 0.35 | Happy / Engaged |
| neutral > 0.45 | Focused / Neutral |
| else | Confused |

This label is **supportive only** â€” the confusion score is primary.

---

# ðŸ“¡ Output JSON Per Frame

```json
{
  "face_count": 1,
  "status": "OK",
  "emotion": "Focused / Neutral",
  "happy_prob": 0.42,
  "gaze": "CENTER",
  "confused": true,
  "confusion_score": 0.67
}
```

---

# ðŸ§ª Edge Cases Handled

âœ” No face  
âœ” Multiple faces  
âœ” Lighting changes  
âœ” Camera disconnect  
âœ” Network loss  
âœ” FER errors gracefully handled  

---

# ðŸ“Š Teacher Dashboard

Shows:

ðŸŸ¢ Focused  
ðŸŸ¡ Confused  
ðŸ”´ Proctor Alert  

Plus a live timeline.

---

# ðŸš€ Run Everything

Backend:

```bash
cd Backend
uvicorn main:app --reload
```

Frontend:

```bash
cd Frontend
npm run dev
```

Open:

```
http://localhost:3000
```

---

# ðŸ”® Future Enhancements

ðŸ”¹ Multi-student dashboard  
ðŸ”¹ Audio sentiment  
ðŸ”¹ Adaptive learning feedback  
ðŸ”¹ Enhanced emotion fusion  

---

# âœ… Submission Checklist

âœ” WebSockets used  
âœ” Custom confusion logic  
âœ” Proctor alerts  
âœ” Dashboard UI  
âœ” README + requirements  
âœ” Demo video explaining logic  

